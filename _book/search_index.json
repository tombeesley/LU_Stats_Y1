[["index.html", "Statistics for Psychologists 1 Intro", " Statistics for Psychologists John Towse, Tom Beesley, Margriet Groen, Rob Davies 2021-08-02 1 Intro This is material for Psychology UGs at Lancaster Uni We will be using tidyverse: library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.0 -- ## v ggplot2 3.3.3 v purrr 0.3.4 ## v tibble 3.0.6 v dplyr 1.0.4 ## v tidyr 1.1.2 v stringr 1.4.0 ## v readr 1.4.0 v forcats 0.5.1 ## Warning: package &#39;ggplot2&#39; was built under R version 4.0.3 ## Warning: package &#39;tibble&#39; was built under R version 4.0.3 ## Warning: package &#39;tidyr&#39; was built under R version 4.0.3 ## Warning: package &#39;readr&#39; was built under R version 4.0.3 ## Warning: package &#39;forcats&#39; was built under R version 4.0.3 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() You can do cool stuff like make graphs: mtcars %&gt;% ggplot(aes(x = disp, y = mpg, colour = cyl)) + geom_point() "],["week5.html", "2 Week 6 - group_by and summarise 2.1 Pre-lab work 2.2 Lab Work", " 2 Week 6 - group_by and summarise In this weeks lab we will be recapping some of the commands you learnt in week 3 - group_by() and summarise() - and exploring some of the properties of the binomial distribution using the Sign Test. Please ensure you do the pre-lab work before coming to class. 2.1 Pre-lab work 2.1.1 Online tutorials Complete the online tutorial for working with these commands. These tutorials use a web-based version of R that will allow you to enter commands, and also get hints and solutions to the problems. Once youve completed the tutorial, you can put what youve learnt in to practice in R Studio using the lab tasks below. To access the tutorial click here: https://psylancs.shinyapps.io/Week_6_learnr/ 2.1.2 R Studio prep work In preparation for the lab tasks, please do the following things: Download the data file here Download the data file location_music_Wk6.csv, Week_6_lab.R and Week_6_binomial.R files from the Week 6 lab resources folder on Moodle. Place the two files in a suitable folder on the computer. Within R Studio, navigate to that folder in the Files pane. Select the More button and then Set as Working Directory Optional - create a new project in this folder (File, New Project, Existing Directory) 2.1.3 Conceptual prep work A researcher conducts an experiment to find out if an anti-smoking advert changes the amount people smoke. He has people record the number of cigarettes they smoke for a week before watching the advert, and then for a week after watching the advert. The data are shown below: Participant Before watching the advert After watching the advert 1 25 31 2 10 5 3 8 7 4 35 25 5 48 44 6 21 26 7 29 30 8 17 11 9 26 14 10 41 38 11 44 12 12 73 56 13 4 0 14 8 8 15 33 24 16 22 27 How many positive, negative, and zero differences are there? What is the sample size that is applicable for the Sign Test? What is the critical value in the Sign Test table? What is the null-hypothesis? Can we reject the null-hypothesis? 2.2 Lab Work 2.2.1 R Studio exercises - music preferences (Task 1) Now that you have completed the online tutorials on group_by() and summarise(), its time to put those skills into practice with a new dataset. Open the Week_6_lab.R script (as detailed in the pre-lab work). This will load the tidyverse packages and read in the data. The data consist of the ratings you gave for 8 different musicians, from a score of 1 (Dont like them) through to 5 (Love them!). People could give no opinion, which are coded as NA. So be sure to use na.rm = TRUE when computing your summary statistics. Follow these steps to explore this dataset: Run the two lines of codes library(tidyverse) and data &lt;- read_csv(\"location_music.csv\") Use summary() to get an overview of the data View the responses to nominal variables with count() For an artist of your choice, calculate the mean and SD of their ratings. Use group_by() and summarise() to see whether peoples home location changes their ratings for an artist of your choice. What about conversation skills? Are those who think they have poor conversation skills more likely to prefer rock or pop music? 2.2.2 Exploring binomial distributions and the sign test (Task 2). Download the Week_6_binomial.R script from the Moodle forum. This is a version of the binomial program that Tom used in his lecture this week. It allows you to set the size of the sample e, and generate the binomial probabilities of different results for that sample size. It then plots those probabilities as a column graph using geom_col(). The red line shows the significance level and allows you to see which events are unusual given the null hypothesis for the given sample size (i.e., which bars are below this line) and for a specified Type 1 error rate (alpha). The probabilities for the different results are also presented in blue. Would a result of 3 positive and and 13 negative be deemed statistically significant at the 5% level? Use the script to generate this result and compare the graph to the appropriate number in the Sign Test table below. Would the result be significant at the 1% level? What does this tell you about setting the Type 1 error rate at 1%? With a sample size of 12, use the Sign Test table below to note how many positive or negative results would be deemed unusual under the null hypothesis, at the 5%? Run a sample of 12 in the script to check and compare your answer to 4. For a sample of 8, what significance level (Type 1 error rate; alpha) would we need to set for a result of 2 out of 8 to be deemed statistically significant? Why might this be a poor criterion for our Type 1 error rate? 2.2.3 The Sign Test table sign test table "],["week-7-psyc121-lab.html", "3 Week 7 - PSYC121 lab 3.1 Pre-lab work 3.2 LAB TASK 1: Online tutorials 3.3 LAB TASK 2: R Studio exercises - visualising phone use 3.4 LAB TASK 3: Conducting a one-sample t-test. 3.5 The t-test table (criterion values of t)", " 3 Week 7 - PSYC121 lab They say a picture paints a thousand words, so in this weeks lab we will be learning some fundamental skills in data visualisation with the ggplot() commands. We will also be looking at how we can run one-sample t-tests in R and we will use these to explore the estimates people gave for the median salary in the UK. Please ensure you do the pre-lab work before coming to class. 3.1 Pre-lab work 3.1.1 R Studio prep work In preparation for Tasks 2 and 3, please do the following things: Download all the files in the Week 7 lab folder on Moodle. Place the files in a suitable folder on the computer. Within R Studio, navigate to that folder in the Files pane and click OPEN (note the files are not shown in the folder) Select the More button and then Set as Working Directory Optional - create a new project in this folder (File, New Project, Existing Directory) 3.1.2 Conceptual prep work A researcher conducts an experiment in which they ask a group of ten children aged 8 to read as many words as they can in 1 minute. They know from previous studies that children of this age typically read at 120 words per minute. This group of children have been reported as having difficulty with reading and the researchers want to see if their data are unusual. They find that the 10 children show a reading speed of 105, with a SD of 18. What is the expected mean under the null hypothesis? What is the difference between the sample mean and the expected mean (mu)? What is the standard error of the mean? What is the value of t? What is the value for the degrees of freedom? What is the criterion value in the t-test table (see below), at the 5% level? Can we reject the null-hypothesis? 3.2 LAB TASK 1: Online tutorials Task 1 of this lab will use an online tutorial. To access the tutorial click here: https://psylancs.shinyapps.io/Week_7_learnr/ 3.3 LAB TASK 2: R Studio exercises - visualising phone use Now that you have completed the online tutorials on ggplot(), its time to put those skills into practice with a new data set, provided in data_phone.csv. These data are just the phone time variables (estimated and actual) with the phone type nominal variable. Follow these steps to visualise these data: Open the script Week_7_Task_2.R (see prep work) Run the first two lines of code library(tidyverse) and data &lt;- read_csv(\"data_phone.csv\") View the data with view(data) Inside the aes() command, map the variable screen_time_estimate to the x axis, and the variable screen_time_actual to the y axis. In general, does it look like peoples estimates were accurate? Add a setting for colour outside of the aes(), to make all the points red. Map the colour to the variable phone_type (within aes()). Can you see any differences between people who have different phones? Change the axis titles and add a title for the graph using the labs() command. Change the theme of the graph. 3.4 LAB TASK 3: Conducting a one-sample t-test. In this task we will run some one-sample t-tests in R to examine peoples estimates of UK salaries. Open the Week_7_Task_3.R script (see prep work) Run the first two lines of code library(tidyverse) and data &lt;- read_csv(\"data_salary.csv\") Run the third command. This runs a t-test on the salary estimates. The two settings (parameters) in the t-test function are x, which is the column of data we are interested in testing, and mu, which is the value we want to compare against. Look at the output of the t-test. What does the t value indicate? Check the value against the criterion value in the t-test below (our N = 205, so use value for infinity). The p value tells you precisely how likely the data are, if the null hypothesis was true. Would we say this is statistically significant? Use the 4th command to filter the data to just those participants whose home location is the UK. Run the t-test on these data (you can copy the command, but note you will need to change the name of the data) In the same way as for Q6, check the salary ratings for those people whose home location is Asia and Europe (not UK). Note in each case what the t-test is telling you. 3.5 The t-test table (criterion values of t) "],["week-8-psyc121-lab.html", "4 Week 8 - PSYC121 lab 4.1 Pre-lab work 4.2 LAB TASK 1: Online tutorials 4.3 LAB TASK 2: Exploring the Stroop effect 4.4 LAB TASK 3: Testing if the differences are real. 4.5 The t-test table (criterion values of t)", " 4 Week 8 - PSYC121 lab Today we will continue to develop our skills in data visualisation with the ggplot() commands. We will look at plotting means and standard errors, and at how geoms can share aesthetic mappings. We will explore our data on the famous Stroop Task and calculate 4.1 Pre-lab work 4.1.1 R Studio prep work If you feel it may be useful, you can work through Task 1 before the lab class. In preparation for Tasks 2 and 3, please do the following things: Download all the files in the Week 8 lab folder on Moodle. Place the files in a suitable folder on the computer. Within R Studio, navigate to that folder in the Files pane and click OPEN (note the files are not shown in the folder) Select the More button and then Set as Working Directory Optional - create a new project in this folder (File, New Project, Existing Directory) 4.1.2 Conceptual prep work A researcher wants to replicate a published finding that submerging your arm into freezing cold water for 60 seconds impaires your ability to memorise lists of words. They have 15 people complete the memory test before and after submerging their arm. The mean score before is 17 items correct, and the mean score after is 12 items correct. The SD of the difference scores is 9. What is the null hypothesis? What is the mean difference score? What is the SE of the difference scores? What is the t value? What are the degrees of freedom? What is the criterion value for t? (see table below) Is our t value significant? Is this a directional hypothesis? And what does that mean for our criterion value? 4.2 LAB TASK 1: Online tutorials Task 1 of this lab will use an online tutorial. To access the tutorial click here: https://psylancs.shinyapps.io/Week_8_learnr/ 4.3 LAB TASK 2: Exploring the Stroop effect The Stroop Effect is a classic demonstration of automaticity of behaviour. Participants have to say the colour a word is printed in, which is an easy task for a compatible stimulus like , and a much more difficult task for an incompatible stimulus like . We cant help but read the text - it has seemingly become an automatic process. In this task we will calculate the means and standard errors of the means. We will then plot them using ggplot(). Open the script Week_8_Tasks.R (see prep work) Run the first two lines of code library(tidyverse) and data &lt;- read_csv(\"data_stroop.csv\") View the data with view(data). You will see that the data are a little different from the data we have worked with previously. We have an ID variable, which gives a unique number for each person. Each person has 3 rows. This is because the different conditions of the stroop task is a within-subjects variable. For data like this it is often useful to have them arranged in what is referred to as long format, with multiple rows for each response the participant provided. For the current data that means we have a variable called stroop_condition, which is our IV, and one called stroop_time which is our DV. Return to the Week_8_Tasks.R script. You will see we have provided you with the scaffold of a complete analysis process for the Stroop data. The raw data will be grouped and then summarised as means and SEs, and then plotted with columns and error bars. This is very similar to the commands used at the end of the learnr tutorial, and you can refer to that analysis if you get stuck here. Your job is to carefully work through the code and fill in the parts that are marked MISSING. By the end, you should have a graph with 3 columns, with the standard error of the means plotted on top. Add a labs() layer to the plot to change the axis titles, and the title of the plot. Change the theme of the plot Map the fill aesthetic to the variable stroop_condition Manually change the colours of the columns with (e.g.) scale_fill_manual(values = c(\"darkgreen\", \"darkblue\", \"darkred\")). Open the RColor.pdf in the Week 8 files for more colours than youll probably ever want! Click Export-&gt;Save as Image. Then show it off to the world (i.e., the Teams channel) 4.4 LAB TASK 3: Testing if the differences are real. To test whether people performed differently in the different Stroop conditions, we can run a series of related samples t-tests. We will use a slightly modified version of our command for conducting the one-sample t-test in Week 7. First though, we must use a filter() to restrict the data to just two conditions on the stroop_condition variable. This is because a related samples t-test looks at the difference between two means (and only two), so the column we use needs to have just two levels. Continue working with the Week_8_Tasks.R script Use the filter command to restrict the data to two of the conditions. Note that the filter uses an | symbol, which means or. Run the t-test on this selection of data, to compare the means from these two levels of the IV. Is the result significant? Note the t value and the p value. How would you express this as a statement in a report? With 3 levels to the variable stroop_condition there are 3 possible comparisons we can make. Complete these by copying and pasting the commands, editing each to make a different filter selection, and then run the t-test. Make sure you interpret the results of the t-tests. 4.5 The t-test table (criterion values of t) "],["week-9-psyc121-lab.html", "5 Week 9 - PSYC121 lab 5.1 Pre-lab work 5.2 LAB TASK 1: Online tutorials 5.3 LAB TASK 2: 5.4 The t-test table (criterion values of t)", " 5 Week 9 - PSYC121 lab Today we will do some work on checking data for unusual values, determining what is an outlier and removing those data before our analysis. In order to achieve this important step, we will learn a bit more about filtering data using the filter() command, and learn a new function, mutate(), which creates new columns. 5.1 Pre-lab work 5.1.1 R Studio prep work If you feel it may be useful, you can work through Task 1 before the lab class. In preparation for Task 2, please do the following things: Download all the files in the Week 8 lab folder on Moodle. Place the files in a suitable folder on the computer. Within R Studio, navigate to that folder in the Files pane and click OPEN (note the files are not shown in the folder) Select the More button and then Set as Working Directory Optional - create a new project in this folder (File, New Project, Existing Directory) 5.1.2 Conceptual prep work This work gets you to play with the power calculations in R, as shown in the final slide of the lecture this week. Start a new R Studio script and complete the following queries: Add a line library(pwr) and run this add the line pwr.t.test(d = .5, n = 100) and run this. What is the reported power value and what does this mean? If you want to achieve 99% power to see an effect of .3, what sample size do you need? With a sample size of 60 and power of 80%, what minimum effect size would we be able to detect? 5.2 LAB TASK 1: Online tutorials Task 1 of this lab will use an online tutorial. To access the tutorial click here: https://psylancs.shinyapps.io/Week_9_learnr/ (not available until Monday morning) 5.3 LAB TASK 2: In this task we will look at the data for UK median salary estimates, and focus first on exploring the sample in order to identify and potentially remove any unusual data. Open the script Week_9_Tasks.R (see prep work) Run the first two lines of code library(tidyverse) and data &lt;- read_csv(\"gamble_salary.csv\") Add a geom_boxplot() to the ggplot() command to draw a box and whiskers plot, mapping the variable salary_estimate to either the x OR y axis. Note the outliers that are shown - we will now try to identify these data points and remove them. Add a new column (mutate()) to the data set, which uses the scale function to transform the salary estimates into z-scores. Complete the arrange(desc()) to have the data sorted by the z-score column (use whatever name you made that column in the mutate command). Use view(data) to view the data set and get a sense of the data. Now that we have the salary estimates recoded as z-scores, we can think about what we might consider an extreme data point. If we remove z scores that are &gt;2 and &lt;-2 we will be removing ~5% of the extreme values. Lets take a look at how many results have these extreme z values in our sample. Complete the two filter commands, one to see how many results give z-scores over 2, and one to see how many results give z-scores under -2. You should see 6 at the high end, and 11 at the low end. Once you are happy with how the filters are working, use a filter command to remove these outliers from the data. We will look at the salary estimates, as a function of whether respondants were risk-seeking or more risk-averse. You may remember that you were asked the following question: Imagine you are on a game-show and you win £300. The presenter gives you have a choice: receive an additional £100 for sure, or take a gamble offering a 50% chance to gain £200 and a 50% chance to gain nothing. Which would you choose? The classic finding is that around 80% of people play it safe and dont gamble. Whether people in our sample chose to gamble or not, is coded in the column gamble_gain (TRUE = gamble, FALSE = dont gamble). Complete the group_by and summarise commands to assess whether the mean salary estimates differed between people who were risk-takers and those who were more risk-averse. Note that the summarise command includes a calculation of N, showing the number of each response: did our sample fit the original finding of ~80% people playing it safe? Run a unrelated (paired = FALSE) t-test on the data to see if people who are more risk averse or risk-seeking give different salary estimates. For those interested in the gambling variable, note that we asked a second version of the same scenario: Imagine you are on a different game-show and you win £500. Here you are given a choice between either losing £100 from your winnings for sure, or taking a gamble offering a 50% chance to lose nothing and a 50% chance to lose £200. Which would you choose? When phrased as a loss, more people tend to gamble. Did our sample show this result? Were the salary estimates of people who were willing to gamble under this scenario different to those not willing to gamble? Use the same formula you used in the t-statistic in the calculation of Cohens d. What is the effect size? Work out what our final sample size was in the data after we conducted the filtering (hint: look in the environment). Use this to conduct a power analysis to see what effect size we could have seen with a power of 80%. 5.4 The t-test table (criterion values of t) "]]
